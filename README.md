# オレオレLVM
- Twitterから落としたアーカイブの`tweets.js`の一行目を適当にいじって`tweets.json`にする
- 順番に実行

- ここも見られ https://huggingface.co/Ogawa34/mineVLM

## 例
[ワイのTwitter](https://x.com/Ogawa3427/status/1900188332501721225)

## しくみ
1. データの準備
- Twitterアーカイブから画像付きツイートを抽出 (`01list.py`)
- 画像を64x64にリサイズし、URLを除去したテキストとペアにして保存 (`02resize.py`)

2. トークナイザーの学習とデータセット作成
- テキストコーパスからSentencePieceでトークナイザーを学習 (`03token.py`)
- 画像とテキストのペアをトークナイズしてデータセットを作成

3. モデルアーキテクチャ
- CNN: 画像を64x64から特徴量に変換
  - 2層のConv+MaxPool構造
  - 最終的に512次元の特徴量に変換
- LSTM: 画像特徴量を初期状態として、テキスト生成
  - Embedding層 (256次元)
  - 単方向LSTM (512次元)
  - 出力層 (vocab_size)

4. 学習
- クロスエントロピー損失で最適化
- バッチサイズ32
- 10エポック
- Adam optimizer (lr=1e-4)

5. 推論
- 画像から特徴量を抽出
- BOSトークンから開始して、確率的にトークンを生成
- EOSトークンが出るか最大長に達するまで生成
- temperature=0.7で多様な生成を実現

## web使い方
- ↑からモデルをダウンロードしてルートに置いとく
- `flask run`でサーバー起動
